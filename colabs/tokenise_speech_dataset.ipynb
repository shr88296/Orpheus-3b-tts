{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salty-muffin/Orpheus-TTS/blob/main/colabs/tokenise_speech_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uX_IoEpnnL2"
      },
      "outputs": [],
      "source": [
        "# Change these\n",
        "\n",
        "my_original_dataset_name = \"canopylabs/zac-sample-dataset\"\n",
        "\n",
        "\n",
        "## CHANGE TO YOUR NAMESPACE\n",
        "name_to_push_dataset_to = \"<my-namespace>/zac_sample-dataset-tokenised\"\n",
        "\n",
        "\n",
        "## CHANGE TO YOUR HUGGINGFACE TOKEN\n",
        "!huggingface-cli login --token=<your token>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Y1BlCraIs9bh",
        "outputId": "e82400d5-3795-4b56-c7b7-c1d639ceb411"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'my_original_dataset_name' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-97ed5d2ce031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_original_dataset_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m snapshot_download(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_original_dataset_name' is not defined"
          ]
        }
      ],
      "source": [
        "#@title Installation & Setup\n",
        "%%capture\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install datasets\n",
        "!pip install snac\n",
        "import torch\n",
        "from snac import SNAC\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import snapshot_download\n",
        "from datasets import load_dataset\n",
        "\n",
        "dsn = my_original_dataset_name\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=dsn,\n",
        "    repo_type=\"dataset\",\n",
        "    revision=\"main\",\n",
        "    max_workers=64,\n",
        ")\n",
        "\n",
        "\n",
        "ds = load_dataset(dsn, split=\"train\")\n",
        "ds_sample_rate = ds[0][\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
        "model = model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kbZENwXltYSC"
      },
      "outputs": [],
      "source": [
        "#@title Tokenisation Function\n",
        "import torchaudio.transforms as T\n",
        "def tokenise_audio(waveform):\n",
        "  waveform = torch.from_numpy(waveform).unsqueeze(0)\n",
        "  waveform = waveform.to(dtype=torch.float32)\n",
        "  resample_transform = T.Resample(orig_freq=ds_sample_rate, new_freq=24000)\n",
        "  waveform = resample_transform(waveform)\n",
        "\n",
        "  waveform = waveform.unsqueeze(0).to(\"cuda\")\n",
        "\n",
        "  #generate the codes from snac\n",
        "  with torch.inference_mode():\n",
        "    codes = model.encode(waveform)\n",
        "\n",
        "  all_codes = []\n",
        "  for i in range(codes[0].shape[1]):\n",
        "    all_codes.append(codes[0][0][i].item()+128266)\n",
        "    all_codes.append(codes[1][0][2*i].item()+128266+4096)\n",
        "    all_codes.append(codes[2][0][4*i].item()+128266+(2*4096))\n",
        "    all_codes.append(codes[2][0][(4*i)+1].item()+128266+(3*4096))\n",
        "    all_codes.append(codes[1][0][(2*i)+1].item()+128266+(4*4096))\n",
        "    all_codes.append(codes[2][0][(4*i)+2].item()+128266+(5*4096))\n",
        "    all_codes.append(codes[2][0][(4*i)+3].item()+128266+(6*4096))\n",
        "\n",
        "\n",
        "  return all_codes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yv9OPDpRwWOy"
      },
      "outputs": [],
      "source": [
        "#@title Map Tokenize\n",
        "import random\n",
        "def add_codes(example):\n",
        "    # Always initialize codes_list to None\n",
        "    codes_list = None\n",
        "\n",
        "    try:\n",
        "        answer_audio = example.get(\"audio\")\n",
        "        # If there's a valid audio array, tokenise it\n",
        "        if answer_audio and \"array\" in answer_audio:\n",
        "            audio_array = answer_audio[\"array\"]\n",
        "            codes_list = tokenise_audio(audio_array)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping row due to error: {e}\")\n",
        "        # Keep codes_list as None if we fail\n",
        "    example[\"codes_list\"] = codes_list\n",
        "\n",
        "    return example\n",
        "\n",
        "ds = ds.map(add_codes, remove_columns=[\"audio\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2G9uppg0H3-X"
      },
      "outputs": [],
      "source": [
        "#@title Load Tokenizer\n",
        "tokeniser_length = 128256\n",
        "start_of_text = 128000\n",
        "end_of_text = 128009\n",
        "\n",
        "start_of_speech = tokeniser_length + 1\n",
        "end_of_speech = tokeniser_length + 2\n",
        "\n",
        "start_of_human = tokeniser_length + 3\n",
        "end_of_human = tokeniser_length + 4\n",
        "\n",
        "start_of_ai = tokeniser_length + 5\n",
        "end_of_ai =  tokeniser_length + 6\n",
        "pad_token = tokeniser_length + 7\n",
        "\n",
        "audio_tokens_start = tokeniser_length + 10\n",
        "\n",
        "tokenizer_name = \"canopylabs/orpheus-3b-0.1-pretrained\"\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "num_proc = os.cpu_count() - 2\n",
        "\n",
        "ds = ds.filter(lambda x: x[\"codes_list\"] is not None)\n",
        "ds = ds.filter(lambda x: len(x[\"codes_list\"]) > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hWGtOc5QIPcn"
      },
      "outputs": [],
      "source": [
        "#@title Create Input Ids\n",
        "def remove_duplicate_frames(example):\n",
        "    vals = example[\"codes_list\"]\n",
        "    if len(vals) % 7 != 0:\n",
        "        raise ValueError(\"Input list length must be divisible by 7\")\n",
        "\n",
        "    result = vals[:7]\n",
        "\n",
        "    removed_frames = 0\n",
        "\n",
        "    for i in range(7, len(vals), 7):\n",
        "        current_first = vals[i]\n",
        "        previous_first = result[-7]\n",
        "\n",
        "        if current_first != previous_first:\n",
        "            result.extend(vals[i:i+7])\n",
        "        else:\n",
        "            removed_frames += 1\n",
        "\n",
        "    example[\"codes_list\"] = result\n",
        "\n",
        "    return example\n",
        "\n",
        "ds = ds.map(remove_duplicate_frames, num_proc=num_proc)\n",
        "\n",
        "tok_info = '''*** HERE you can modify the text prompt\n",
        "i.e. if you wanted a multispeaker model like canopylabs/orpheus-3b-0.1-ft, you can pass:\n",
        "f\"{example[\"source\"]}:  {example[\"text\"]}\", as is passed.\n",
        "'''\n",
        "print(tok_info)\n",
        "\n",
        "def create_input_ids(example):\n",
        "    text_ids = tokenizer.encode(example[\"text\"],  add_special_tokens=True)\n",
        "    text_ids.append(end_of_text)\n",
        "    example[\"text_tokens\"] = text_ids\n",
        "    input_ids = (\n",
        "        [start_of_human]\n",
        "        + example[\"text_tokens\"]\n",
        "        + [end_of_human]\n",
        "        + [start_of_ai]\n",
        "        + [start_of_speech]\n",
        "        + example[\"codes_list\"]\n",
        "        + [end_of_speech]\n",
        "        + [end_of_ai]\n",
        "    )\n",
        "    example[\"input_ids\"] = input_ids\n",
        "    example[\"labels\"] = input_ids\n",
        "    example[\"attention_mask\"] = [1] * len(input_ids)\n",
        "\n",
        "    return example\n",
        "\n",
        "ds = ds.map(create_input_ids, num_proc=num_proc, remove_columns=[\"text\", \"codes_list\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ee3zbdCUIWV6"
      },
      "outputs": [],
      "source": [
        "#@title Remove unnecessary columns\n",
        "columns_to_keep = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "columns_to_remove = [col for col in ds.column_names if col not in columns_to_keep]\n",
        "\n",
        "ds = ds.remove_columns(columns_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov_2ItW6nldr"
      },
      "outputs": [],
      "source": [
        "ds.push_to_hub(name_to_push_dataset_to)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
